{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('t8.shakespeare.txt', 'r') as file:\n",
    "    # Initialize a counter\n",
    "    line_count = 0\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Increment the counter for each line\n",
    "        line_count += 1\n",
    "\n",
    "print(f'The file has {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docdist1.py\n",
    "#\n",
    "#\n",
    "# This program computes the \"distance\" between two text files\n",
    "# as the angle between their word frequency vectors.\n",
    "#\n",
    "# For each input file, a word-frequency vector is computed as follows:\n",
    "#    (1) the specified file is read in\n",
    "#    (2) it is converted into a list of alphanumeric \"words\"\n",
    "#        Here a \"word\" is a sequence of consecutive alphanumeric\n",
    "#        characters.  Non-alphanumeric characters are treated as blanks.\n",
    "#        Case is not significant.\n",
    "#    (3) for each word, its frequency of occurrence is determined\n",
    "#    (4) the word/frequency lists are sorted into order alphabetically\n",
    "#\n",
    "# The \"distance\" between two vectors is the angle between them.\n",
    "# If x = (x1, x2, ..., xn) is the first vector (xi = freq of word i)\n",
    "# and y = (y1, y2, ..., yn) is the second vector,\n",
    "# then the angle between them is defined as:\n",
    "#    d(x,y) = arccos(inner_product(x,y) / (norm(x)*norm(y)))\n",
    "# where:\n",
    "#    inner_product(x,y) = x1*y1 + x2*y2 + ... xn*yn\n",
    "#    norm(x) = sqrt(inner_product(x,x))\n",
    "\n",
    "import math\n",
    "    # math.acos(x) is the arccosine of x.\n",
    "    # math.sqrt(x) is the square root of x.\n",
    "\n",
    "import string\n",
    "    # string.join(words,sep) takes a given list of words,\n",
    "    #    and returns a single string resulting from concatenating them\n",
    "    #    together, separated by the string sep .\n",
    "    # string.lower(word) converts word to lower-case\n",
    "\n",
    "import sys\n",
    "    # sys.exit() allows us to quit (if we can't read a file)\n",
    "\n",
    "# Operation 1: read a text file ##\n",
    "##################################\n",
    "def read_file(filename):\n",
    "    ###    Read the text file with the given filename;\n",
    "    ###     return a list of the lines of text in the file.\n",
    "    try:\n",
    "        fp = open(filename)\n",
    "        L = fp.readlines()\n",
    "    except IOError as excObj:\n",
    "        print(str(excObj))\n",
    "        print(\"Error opening or reading input file: \" + filename)\n",
    "        sys.exit()\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "1a. How many lines are in assets/t8.shakespeare.txt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('/home/jovyan/work/resources/data/t8.shakespeare.txt', 'r') as file:\n",
    "    # Initialize a counter\n",
    "    line_count = 0\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Increment the counter for each line\n",
    "        line_count += 1\n",
    "\n",
    "print(f'The file has {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "The file has 124456 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "1b. How many lines are in assets/t5.churchill.txt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('/home/jovyan/work/resources/data/t5.churchill.txt', 'r') as file:\n",
    "    # Initialize a counter\n",
    "    line_count = 0\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Increment the counter for each line\n",
    "        line_count += 1\n",
    "\n",
    "print(f'The file has {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "The file has 189685 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "2. In the function word_frequencies_for_file(...), where is most of the time spent?\n",
    "\n",
    "    > read_file(...)\n",
    "    > get_words_from_line_list(...)\n",
    "    - count_frequency(...)\n",
    "    > insertion_sort(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "3. Which of the following commands would result in output that looks similar to:\n",
    "\n",
    "        102 ms ± 1.98 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "    \n",
    "    - %%timeit\n",
    "    document_similarity('assets/short.t1.txt','assets/short.t2.txt')\n",
    "    - %timeit  document_similarity('assets/short.t1.txt','assets/short.t2.txt')\n",
    "    > %lprun -f document_similarity document_similarity('assets/short.t1.txt','assets/short.t2.txt')\n",
    "    > %lprun -f __main__ document_similarity('assets/short.t1.txt','assets/short.t2.txt')\n",
    "    > Any of the above would generate this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "**Explanation**\n",
    "> %timeit document_similarity('assets/short.t1.txt','assets/short.t2.txt')\n",
    "\n",
    "The %timeit magic command in IPython or Jupyter Notebook is used to time the execution of a single statement. It runs the statement multiple times to get a more accurate measurement of the execution time, providing the mean and standard deviation of the runs.\n",
    "\n",
    "The other commands listed do not produce this specific type of output:\n",
    "\n",
    "    - %lprun -f document_similarity document_similarity('assets/short.t1.txt','assets/short.t2.txt') and %lprun -f __main__ document_similarity('assets/short.t1.txt','assets/short.t2.txt') are used with the line_profiler to profile the function line by line, but they do not produce the same output format as %timeit.\n",
    "\n",
    "So, the correct command is %timeit document_similarity('assets/short.t1.txt','assets/short.t2.txt') AND %%timeit    \n",
    "document_similarity('assets/short.t1.txt', 'assets/short.t2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "4. What order is count_frequency()?\n",
    "\n",
    "    > O(1)\n",
    "    > O(n)\n",
    "    - O(n^2)\n",
    "    > O(nlogn)\n",
    "    > O(2^n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## I think there may be an error with this question\n",
    "**Explanation**\n",
    "\n",
    "The correct answer is O(n), as the function's runtime grows linearly with the number of words in the input list. The answer O(n^2) is incorrect because the function does not involve nested loops or operations that would result in quadratic time complexity.\n",
    "\n",
    "## I originally chose O(n) but the autograder said it was incorrect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "5. Let's say that you have two files that were the same size and running document_similarity() on them took 18 seconds to complete.  If you then ran document_similarity() on two different files, each of which was twice the size of the original files, and it took 72 seconds to complete, what would that tell you about the order of the overall script?\n",
    " \n",
    "    > It's O(n)\n",
    "    - It's O(n^2)\n",
    "    > There isn't enough information to know anything about the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "**Explanation**\n",
    "    - Initial Run: Two files of size n take 18 seconds to complete.\n",
    "    - Second Run: Two files of size 2n take 72 seconds to complete.\n",
    "\n",
    "When the input size is doubled, the runtime increases by a factor of four (from 18 seconds to 72 seconds). This quadratic increase indicates that the time complexity is proportional to the square of the input size, which is characteristic of O(n^2) complexity.\n",
    "\n",
    "So, the correct answer is:\n",
    "\n",
    "> It's O(n^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "6. What would happen if you used a dictionary instead of a list in count_frequencies?\n",
    "\n",
    "    > The total run time would increase.\n",
    "    > The total run time would stay the same.\n",
    "    - The total run time would decrease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "**Explanation**\n",
    "\n",
    "    - List-Based Approach: When using a list to count frequencies, you need to iterate through the list to check if a word already exists. This results in a time complexity of O(n^2) in the worst case, where n is the number of words in the list.\n",
    "    - Dictionary-Based Approach: Using a dictionary allows for average O(1) time complexity for both checking if a word exists and updating its count. This results in an overall time complexity of O(n) for the function, where n is the number of words in the list.\n",
    "\n",
    "By using a dictionary, you significantly reduce the time complexity and improve the efficiency of the function. This is because dictionaries provide faster lookups and updates compared to lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "7. Without modifying the code, how long does document_similarity('assets/t1.verne.txt','assets/t2.bobsey.txt') take to run?  Copy your output from %timeit exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output\n",
    "102 ms ± 1.98 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "8. Now, based on the information in the questions you answered above, do your best to improve the efficiency of the code.  You can refactor the code but you must be able to call document_similarity('assets/t1.verne.txt','assets/t2.bobsey.txt') . Copy the output of %timeit document_similarity('assets/t1.verne.txt','assets/t2.bobsey.txt')  into the space below.\n",
    "\n",
    "You are expected to report run times that are better (i.e. faster) than the unimproved versions.  We are looking for any improvement; we do not expect you to achieve a certain factor (e.g. 1.5x, 2x, 3x, etc.), just some improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "\n",
    "# Operation 1: Read a text file\n",
    "def read_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return file.readlines()\n",
    "    except IOError as excObj:\n",
    "        print(str(excObj))\n",
    "        print(\"Error opening or reading input file: \" + filename)\n",
    "        sys.exit()\n",
    "\n",
    "# Operation 2: Convert lines to words\n",
    "def get_words_from_line_list(L):\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    word_list = []\n",
    "    character_list = []\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif character_list:\n",
    "            word = ''.join(character_list).lower()\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if character_list:\n",
    "        word = ''.join(character_list).lower()\n",
    "        word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "# Operation 3: Count frequency of each word\n",
    "def count_frequency(word_list):\n",
    "    frequency_dict = {}\n",
    "    for word in word_list:\n",
    "        if word in frequency_dict:\n",
    "            frequency_dict[word] += 1\n",
    "        else:\n",
    "            frequency_dict[word] = 1\n",
    "    return list(frequency_dict.items())\n",
    "\n",
    "# Operation 4: Sort words into alphabetic order\n",
    "def insertion_sort(A):\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        i = j - 1\n",
    "        while i > -1 and A[i] > key:\n",
    "            A[i + 1] = A[i]\n",
    "            i = i - 1\n",
    "        A[i + 1] = key\n",
    "    return A\n",
    "\n",
    "# Operation 5: Compute inner product\n",
    "def inner_product(L1, L2):\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < len(L1) and j < len(L2):\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return sum\n",
    "\n",
    "# Operation 6: Compute vector norm\n",
    "def vector_norm(L):\n",
    "    sum = 0.0\n",
    "    for word, freq in L:\n",
    "        sum += freq ** 2\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "# Operation 7: Compute document distance\n",
    "def document_similarity(filename_1, filename_2, verbose=True):\n",
    "    L1 = read_file(filename_1)\n",
    "    L2 = read_file(filename_2)\n",
    "    \n",
    "    words1 = get_words_from_line_list(L1)\n",
    "    words2 = get_words_from_line_list(L2)\n",
    "    \n",
    "    freq1 = count_frequency(words1)\n",
    "    freq2 = count_frequency(words2)\n",
    "    \n",
    "    sorted_freq1 = insertion_sort(freq1)\n",
    "    sorted_freq2 = insertion_sort(freq2)\n",
    "    \n",
    "    inner_prod = inner_product(sorted_freq1, sorted_freq2)\n",
    "    norm1 = vector_norm(sorted_freq1)\n",
    "    norm2 = vector_norm(sorted_freq2)\n",
    "    \n",
    "    distance = math.acos(inner_prod / (norm1 * norm2))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Document Distance: {distance}\")\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "filename1 = 'assets/t1.verne.txt'\n",
    "filename2 = 'assets/t2.bobsey.txt'\n",
    "\n",
    "# Measure the execution time\n",
    "%timeit document_similarity(filename1, filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output\n",
    "730 ms ± 6.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_similarity('assets/short.t1.txt','assets/short.t2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output without optimization\n",
    "0.7776941793778887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "    - Using with open: Ensures the file is properly closed after reading.\n",
    "    - Optimized Word Frequency Counting: Using a dictionary for counting word frequencies improves efficiency.\n",
    "    - Efficient Sorting: The insertion sort is retained, but you can replace it with Python's built-in sorted() function for better performance if needed."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
